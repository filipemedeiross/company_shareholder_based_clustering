{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIPARTITE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "PARQUET_BUSINESS = '../data/parquet/business.parquet'\n",
    "\n",
    "table = pq.ParquetFile(PARQUET_BUSINESS)\n",
    "print(table.num_row_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PARTNERS  = '../data/parquet/partners.parquet'\n",
    "OUTPUT_COMPANIES = '../data/parquet/companies.parquet'\n",
    "OUTPUT_BUSINESS  = '../data/parquet/business.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = pd.read_csv(\n",
    "    '../data/csv/empresas/empresas0.csv',\n",
    "    sep=';',\n",
    "    usecols=[4],\n",
    "    names=['capital'],\n",
    "    nrows=1000000,\n",
    "    low_memory=False      ,\n",
    "    encoding='latin-1'    ,\n",
    "    on_bad_lines='skip'   ,\n",
    ")\n",
    "\n",
    "chunk.capital = (\n",
    "    chunk.capital\n",
    "    .str\n",
    "    .replace(r',.*', '', regex=True)\n",
    "    .astype('int64')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110120     26205000000\n",
       "234296     18000000000\n",
       "390266      7550178543\n",
       "497019     12672470977\n",
       "500519      5619073324\n",
       "800981    172964347313\n",
       "869063      8043222080\n",
       "869329     24164007439\n",
       "875075     21691206177\n",
       "960158    422451360001\n",
       "990413      6109562304\n",
       "Name: capital, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.capital[chunk.capital > 4294967290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de row_groups: 13\n",
      "Processando row_group 0...\n",
      "Processando row_group 1...\n",
      "Processando row_group 2...\n",
      "Processando row_group 3...\n",
      "Processando row_group 4...\n",
      "Processando row_group 5...\n",
      "Processando row_group 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6263/3132764133.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repetidos['row_group'] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando row_group 7...\n",
      "Processando row_group 8...\n",
      "Processando row_group 9...\n",
      "Processando row_group 10...\n",
      "Processando row_group 11...\n",
      "Processando row_group 12...\n",
      "Duplicados dentro dos row_groups encontrados:\n",
      "       cnpj  row_group\n",
      "0  10959550          6\n",
      "1  10959550          6\n",
      "2  10959550          6\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "parquet_file = pq.ParquetFile(OUTPUT_COMPANIES)\n",
    "\n",
    "print(f'Total de row_groups: {parquet_file.num_row_groups}')\n",
    "\n",
    "duplicados_por_rg = []\n",
    "for i in range(parquet_file.num_row_groups):\n",
    "    print(f'Processando row_group {i}...')\n",
    "\n",
    "    table = parquet_file.read_row_group(i, columns=['cnpj'])\n",
    "    df = table.to_pandas()\n",
    "\n",
    "    repetidos = df[df.duplicated(subset='cnpj', keep=False)]\n",
    "\n",
    "    if not repetidos.empty:\n",
    "        repetidos['row_group'] = i\n",
    "        duplicados_por_rg.append(repetidos)\n",
    "\n",
    "if duplicados_por_rg:\n",
    "    repetidos_final = pd.concat(duplicados_por_rg, ignore_index=True)\n",
    "    print('Duplicados dentro dos row_groups encontrados:')\n",
    "    print(repetidos_final)\n",
    "else:\n",
    "    print('Nenhum CNPJ duplicado dentro dos row_groups foi encontrado.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnpj_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66349370</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66349371</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66349372</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66349373</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66349374</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66349375 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cnpj_order\n",
       "0                  1\n",
       "1                  1\n",
       "2                  1\n",
       "3                  1\n",
       "4                  1\n",
       "...              ...\n",
       "66349370           1\n",
       "66349371           1\n",
       "66349372           1\n",
       "66349373           1\n",
       "66349374           1\n",
       "\n",
       "[66349375 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = pd.read_parquet(OUTPUT_BUSINESS, columns=['cnpj_order'])\n",
    "business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnpj_order    9999\n",
       "dtype: int16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repetidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_cnpjs = companies[companies.duplicated(subset='cnpj', keep=False)]['cnpj']\n",
    "\n",
    "print(duplicated_cnpjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnpj</th>\n",
       "      <th>name_partner</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2450527</td>\n",
       "      <td>!</td>\n",
       "      <td>19010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048975</th>\n",
       "      <td>2327780</td>\n",
       "      <td>S</td>\n",
       "      <td>19980109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cnpj name_partner  start_date\n",
       "8        2450527            !    19010101\n",
       "2048975  2327780            S    19980109"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partners[partners.name_partner.str.len() < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# PART 4 - Reload both files and rewrite with higher compression\n",
    "# ==============================================================\n",
    "print('Rewriting parquet files with pyarrow compression...')\n",
    "\n",
    "\n",
    "partners.sort_values(\n",
    "    by=[\n",
    "        'start_date'  ,\n",
    "        'name_partner',\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "partners.to_parquet(\n",
    "    OUTPUT_PARTNERS ,\n",
    "    engine='pyarrow',\n",
    "    index=False     ,\n",
    ")\n",
    "\n",
    "del partners\n",
    "\n",
    "\n",
    "business = pd.read_parquet(OUTPUT_BUSINESS)\n",
    "\n",
    "business.sort_values(\n",
    "    by=[\n",
    "        'closing_date',\n",
    "        'opening_date',\n",
    "        'cep'         ,\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "business.to_parquet(\n",
    "    OUTPUT_BUSINESS ,\n",
    "    engine='pyarrow',\n",
    "    index=False     ,\n",
    ")\n",
    "\n",
    "del business\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARING THE ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIPARTITE GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the bipartite graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows processed = 1000000\n",
      "Number of rows processed = 2000000\n",
      "Number of rows processed = 3000000\n",
      "Number of rows processed = 4000000\n",
      "Number of rows processed = 5000000\n",
      "Number of rows processed = 6000000\n",
      "Number of rows processed = 7000000\n",
      "Number of rows processed = 8000000\n",
      "Number of rows processed = 9000000\n",
      "Number of rows processed = 10000000\n",
      "Number of rows processed = 11000000\n",
      "Number of rows processed = 12000000\n",
      "Number of rows processed = 13000000\n",
      "Number of rows processed = 14000000\n",
      "Number of rows processed = 15000000\n",
      "Number of rows processed = 16000000\n",
      "Number of rows processed = 17000000\n",
      "Number of rows processed = 18000000\n",
      "Number of rows processed = 19000000\n",
      "Number of rows processed = 20000000\n",
      "Number of rows processed = 21000000\n",
      "Number of rows processed = 22000000\n",
      "Number of rows processed = 23000000\n",
      "Number of rows processed = 24000000\n",
      "Number of rows processed = 25000000\n"
     ]
    }
   ],
   "source": [
    "cnpj2id    = {}\n",
    "partner2id = {}\n",
    "adjdict    = defaultdict(list)\n",
    "\n",
    "cnpj_id  = 0\n",
    "cnpj_idx = 0\n",
    "partner_id  = 0\n",
    "partner_idx = 0\n",
    "\n",
    "for idx, (cnpj, partner) in enumerate(partners.itertuples(index=False)):\n",
    "    if cnpj not in cnpj2id:\n",
    "        cnpj_idx  = cnpj_id\n",
    "        cnpj_id  += 1\n",
    "\n",
    "        cnpj2id[cnpj] = cnpj_idx\n",
    "    else:\n",
    "        cnpj_idx = cnpj2id[cnpj]\n",
    "\n",
    "    if partner not in partner2id:\n",
    "        partner_idx  = partner_id\n",
    "        partner_id  += 1\n",
    "\n",
    "        partner2id[partner] = partner_idx\n",
    "    else:\n",
    "        partner_idx = partner2id[partner]\n",
    "\n",
    "    adjdict[cnpj_idx].append(partner_idx)\n",
    "\n",
    "    if idx % 1000000 == 999999:\n",
    "        print('Number of rows processed =', idx + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing the data structure of the adjacency list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = [[]] * len(adjdict)\n",
    "\n",
    "for k, v in adjdict.items():\n",
    "    adjacency[k] = v\n",
    "\n",
    "del adjdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cnpj2id.pkl'   , 'wb') as f:\n",
    "    pickle.dump(cnpj2id   , f)\n",
    "\n",
    "with open('../data/partner2id.pkl', 'wb') as f:\n",
    "    pickle.dump(partner2id, f)\n",
    "\n",
    "with open('../data/adjacency.pkl' , 'wb') as f:\n",
    "    pickle.dump(adjacency , f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeing the memory of objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnpj2id\n",
    "del partner2id\n",
    "del adjacency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING THE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of companies and partners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies in the 'partners' file = 14441622\n",
      "Number of partners  in the 'partners' file = 14686766\n"
     ]
    }
   ],
   "source": [
    "print('Number of companies in the \\'partners\\' file =', partners.cnpj.nunique())\n",
    "print('Number of partners  in the \\'partners\\' file =', partners.name_partner.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeing up resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del partners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cnpj2id.pkl'   , 'rb') as f:\n",
    "    cnpj2id = pickle.load(f)\n",
    "\n",
    "with open('../data/partner2id.pkl', 'rb') as f:\n",
    "    partner2id = pickle.load(f)\n",
    "\n",
    "with open('../data/adjacency.pkl' , 'rb') as f:\n",
    "    adjacency = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming the number of companies and partners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies in the 'cnpj2id'    file = 14441622\n",
      "Number of partners  in the 'partner2id' file = 14686766\n"
     ]
    }
   ],
   "source": [
    "print('Number of companies in the \\'cnpj2id\\'    file =', len(cnpj2id   ))\n",
    "print('Number of partners  in the \\'partner2id\\' file =', len(partner2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the partners of a given company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNPJ members 85061877:\n",
      "\n",
      "RICARDO BAULE ROSSI\n",
      "EDUARDO GUILHERME BAULE ROSSI\n"
     ]
    }
   ],
   "source": [
    "CNPJ = 85061877\n",
    "\n",
    "\n",
    "idx      = cnpj2id[CNPJ]\n",
    "partners = set(adjacency[idx])\n",
    "\n",
    "print(f'CNPJ members {CNPJ}:')\n",
    "print()\n",
    "for nome, idx in partner2id.items():\n",
    "    if idx in partners:\n",
    "        partners.remove(idx)\n",
    "\n",
    "        print(nome)\n",
    "\n",
    "    if not partners:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
